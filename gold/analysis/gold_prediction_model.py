import numpy as np
import pandas as pd
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping
import pickle
import os
from datetime import datetime

class GoldPredictionModel:
    """ê¸ˆ ê°€ê²© ì˜ˆì¸¡ ëª¨ë¸ í´ë˜ìŠ¤ - Enhanced Multi-Feature Edition"""
    
    def __init__(self, model_name='../models/gold_prediction_model.h5', 
                 scaler_name='../models/gold_scaler.pkl', sequence_length=60,
                 feature_columns=None):
        self.model_name = model_name
        self.scaler_name = scaler_name
        self.sequence_length = sequence_length
        self.model = None
        self.scaler = None
        self.is_trained = False
        
        # ê¸°ë³¸ íŠ¹ì„± ì»¬ëŸ¼ (ì¢…ê°€ë§Œ ì‚¬ìš©í•˜ëŠ” ê²½ìš°)
        if feature_columns is None:
            self.feature_columns = ['Close']
        else:
            self.feature_columns = feature_columns
            
        self.n_features = len(self.feature_columns)
        
        # í•˜ì´í¼íŒŒë¼ë¯¸í„° ê¸°ë³¸ê°’ ì„¤ì •
        self.lstm_units = [32]
        self.dense_units = [16]
        self.dropout_rates = [0.4, 0.3]
        
        print(f"ğŸ¤– ëª¨ë¸ ì´ˆê¸°í™”:")
        print(f"   ğŸ“Š ì‚¬ìš©í•  íŠ¹ì„±: {self.feature_columns}")
        print(f"   ğŸ”¢ íŠ¹ì„± ê°œìˆ˜: {self.n_features}")
        print(f"   â±ï¸ ì‹œí€€ìŠ¤ ê¸¸ì´: {self.sequence_length}")
        
        # í•œê¸€ í°íŠ¸ ì„¤ì •
        self._setup_korean_font()
    
    def _setup_korean_font(self):
        """í•œê¸€ í°íŠ¸ ìë™ ì„¤ì •"""
        font_candidates = [
            '/System/Library/Fonts/AppleSDGothicNeo.ttc',
            '/usr/share/fonts/truetype/nanum/NanumGothic.ttf',
            'C:/Windows/Fonts/malgun.ttf',
            'AppleGothic', 'Nanum Gothic', 'DejaVu Sans'
        ]
        
        for font in font_candidates:
            try:
                if font.startswith('/') or font.startswith('C:'):
                    if os.path.exists(font):
                        plt.rcParams['font.family'] = fm.FontProperties(fname=font).get_name()
                        break
                else:
                    plt.rcParams['font.family'] = font
                    break
            except:
                continue
        
        plt.rcParams['axes.unicode_minus'] = False
    
    def prepare_data(self, enhanced_data, train_ratio=0.8, target_column='Close'):
        """ë‹¤ì¤‘ íŠ¹ì„± ë°ì´í„° ì „ì²˜ë¦¬ ë° ë¶„í• """
        print("ğŸ”§ ë‹¤ì¤‘ íŠ¹ì„± ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...")
        
        # ì„ íƒëœ íŠ¹ì„±ë“¤ë§Œ ì¶”ì¶œ
        if isinstance(enhanced_data, pd.Series):
            # ë‹¨ì¼ ì‹œë¦¬ì¦ˆì¸ ê²½ìš° (ê¸°ì¡´ í˜¸í™˜ì„±)
            feature_data = enhanced_data.to_frame(name='Close')
            self.feature_columns = ['Close']
            self.n_features = 1
        else:
            # DataFrameì¸ ê²½ìš°
            missing_features = [col for col in self.feature_columns if col not in enhanced_data.columns]
            if missing_features:
                print(f"âš ï¸ ëˆ„ë½ëœ íŠ¹ì„±ë“¤: {missing_features}")
                available_features = [col for col in self.feature_columns if col in enhanced_data.columns]
                print(f"âœ… ì‚¬ìš© ê°€ëŠ¥í•œ íŠ¹ì„±ë“¤: {available_features}")
                self.feature_columns = available_features
                self.n_features = len(self.feature_columns)
            
            feature_data = enhanced_data[self.feature_columns].copy()
        
        # íƒ€ê²Ÿ ì»¬ëŸ¼ í™•ì¸
        if target_column not in enhanced_data.columns:
            print(f"âŒ íƒ€ê²Ÿ ì»¬ëŸ¼ '{target_column}'ì´ ì—†ìŠµë‹ˆë‹¤.")
            return None
            
        target_data = enhanced_data[target_column].copy()
        
        print(f"ğŸ“Š ë°ì´í„° ì •ë³´:")
        print(f"   ğŸ”¢ íŠ¹ì„± ê°œìˆ˜: {self.n_features}")
        print(f"   ğŸ“ˆ ë°ì´í„° í¬ì¸íŠ¸: {len(feature_data)}")
        print(f"   ğŸ¯ íƒ€ê²Ÿ: {target_column}")
        
        # ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ë˜ëŠ” ìƒì„±
        self.scaler = self._load_or_create_scaler(feature_data)
        self.target_scaler = self._load_or_create_target_scaler(target_data)
        
        # ì •ê·œí™”
        scaled_features = self.scaler.transform(feature_data.values)
        scaled_target = self.target_scaler.transform(target_data.values.reshape(-1, 1))
        
        # í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„í• 
        train_size = int(len(scaled_features) * train_ratio)
        train_features = scaled_features[:train_size]
        test_features = scaled_features[train_size:]
        train_target = scaled_target[:train_size]
        test_target = scaled_target[train_size:]
        
        # ì‹œê³„ì—´ ì‹œí€€ìŠ¤ ìƒì„±
        X_train, y_train = self._create_sequences_multivariate(train_features, train_target.flatten())
        X_test, y_test = self._create_sequences_multivariate(test_features, test_target.flatten())
        
        print(f"âœ… ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ:")
        print(f"   í›ˆë ¨ ë°ì´í„°: {X_train.shape}")
        print(f"   í…ŒìŠ¤íŠ¸ ë°ì´í„°: {X_test.shape}")
        print(f"   íŠ¹ì„± ì°¨ì›: {X_train.shape[2]}")
        
        return X_train, y_train, X_test, y_test, (scaled_features, scaled_target), train_size
    
    def _load_or_create_scaler(self, data):
        """íŠ¹ì„±ìš© ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ë˜ëŠ” ìƒì„±"""
        scaler_path = self.scaler_name.replace('.pkl', '_features.pkl')
        
        if os.path.exists(scaler_path):
            print("ğŸ“ ê¸°ì¡´ íŠ¹ì„± ìŠ¤ì¼€ì¼ëŸ¬ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...")
            with open(scaler_path, 'rb') as f:
                scaler = pickle.load(f)
        else:
            print("ğŸ”§ ìƒˆ íŠ¹ì„± ìŠ¤ì¼€ì¼ëŸ¬ ìƒì„± ì¤‘...")
            scaler = MinMaxScaler(feature_range=(0, 1))
            if isinstance(data, pd.DataFrame):
                scaler.fit(data.values)
            else:
                scaler.fit(data.values.reshape(-1, 1))
            with open(scaler_path, 'wb') as f:
                pickle.dump(scaler, f)
        return scaler
    
    def _load_or_create_target_scaler(self, target_data):
        """íƒ€ê²Ÿìš© ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ë˜ëŠ” ìƒì„±"""
        # ìŠ¤ì¼€ì¼ëŸ¬ ì´ë¦„ì´ .pklë¡œ ëë‚˜ì§€ ì•Šìœ¼ë©´ ì¶”ê°€
        if not self.scaler_name.endswith('.pkl'):
            target_scaler_path = self.scaler_name + '_target.pkl'
        else:
            target_scaler_path = self.scaler_name.replace('.pkl', '_target.pkl')
        
        
        if os.path.isfile(target_scaler_path):
            print("ğŸ“ ê¸°ì¡´ íƒ€ê²Ÿ ìŠ¤ì¼€ì¼ëŸ¬ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...")
            with open(target_scaler_path, 'rb') as f:
                scaler = pickle.load(f)
        else:
            print("ğŸ”§ ìƒˆ íƒ€ê²Ÿ ìŠ¤ì¼€ì¼ëŸ¬ ìƒì„± ì¤‘...")
            scaler = MinMaxScaler(feature_range=(0, 1))
            scaler.fit(target_data.values.reshape(-1, 1))
            # ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
            os.makedirs(os.path.dirname(target_scaler_path), exist_ok=True)
            with open(target_scaler_path, 'wb') as f:
                pickle.dump(scaler, f)
        return scaler
    
    def _create_sequences(self, data):
        """ë‹¨ë³€ëŸ‰ ì‹œê³„ì—´ ì‹œí€€ìŠ¤ ìƒì„± (ê¸°ì¡´ í˜¸í™˜ì„±)"""
        X, y = [], []
        for i in range(self.sequence_length, len(data)):
            X.append(data[i-self.sequence_length:i, 0])
            y.append(data[i, 0])
        return np.array(X), np.array(y)
    
    def _create_sequences_multivariate(self, features, target):
        """ë‹¤ë³€ëŸ‰ ì‹œê³„ì—´ ì‹œí€€ìŠ¤ ìƒì„±"""
        X, y = [], []
        for i in range(self.sequence_length, len(features)):
            # íŠ¹ì„±ë“¤ì˜ ì‹œí€€ìŠ¤
            X.append(features[i-self.sequence_length:i])
            # íƒ€ê²Ÿ ê°’
            y.append(target[i])
        return np.array(X), np.array(y)
    
    def build_model(self):
        """ë™ì  í•˜ì´í¼íŒŒë¼ë¯¸í„° ê¸°ë°˜ LSTM ëª¨ë¸ êµ¬ì„±"""
        print(f"ğŸ—ï¸ LSTM ëª¨ë¸ êµ¬ì„± ì¤‘... (íŠ¹ì„± ì°¨ì›: {self.n_features})")
        print(f"   ğŸ”§ LSTM ìœ ë‹›: {self.lstm_units}")
        print(f"   ğŸ”§ Dense ìœ ë‹›: {self.dense_units}")
        print(f"   ğŸ”§ ë“œë¡­ì•„ì›ƒ: {self.dropout_rates}")
        
        layers = []
        
        # LSTM ë ˆì´ì–´ë“¤ êµ¬ì„±
        for i, units in enumerate(self.lstm_units):
            # KerasëŠ” Python intë¥¼ ê¸°ëŒ€í•˜ë¯€ë¡œ ì•ˆì „ ìºìŠ¤íŒ…
            units = int(units)
            if i == 0:
                # ì²« ë²ˆì§¸ LSTM ë ˆì´ì–´
                return_sequences = len(self.lstm_units) > 1
                layers.append(LSTM(
                    units, 
                    return_sequences=return_sequences,
                    input_shape=(self.sequence_length, self.n_features),
                    name=f'lstm_{i+1}'
                ))
            else:
                # ë‚˜ë¨¸ì§€ LSTM ë ˆì´ì–´ë“¤
                return_sequences = i < len(self.lstm_units) - 1
                layers.append(LSTM(
                    int(units),
                    return_sequences=return_sequences,
                    name=f'lstm_{i+1}'
                ))
            
            # ë“œë¡­ì•„ì›ƒ ì¶”ê°€ (ìˆëŠ” ê²½ìš°)
            if i < len(self.dropout_rates):
                layers.append(Dropout(self.dropout_rates[i], name=f'dropout_lstm_{i+1}'))
        
        # Dense ë ˆì´ì–´ë“¤ êµ¬ì„±
        for i, units in enumerate(self.dense_units):
            layers.append(Dense(int(units), activation='relu', name=f'dense_{i+1}'))
            
            # ë“œë¡­ì•„ì›ƒ ì¶”ê°€ (ìˆëŠ” ê²½ìš°)
            dropout_idx = len(self.lstm_units) + i
            if dropout_idx < len(self.dropout_rates):
                layers.append(Dropout(self.dropout_rates[dropout_idx], name=f'dropout_dense_{i+1}'))
        
        # ì¶œë ¥ ë ˆì´ì–´
        layers.append(Dense(1, name='output'))
        
        # ëª¨ë¸ ìƒì„±
        self.model = Sequential(layers)
        
        # ì»´íŒŒì¼ - ë‹¤ì¤‘ íŠ¹ì„±ì— ë§ëŠ” ìµœì í™”
        self.model.compile(
            optimizer='adam',
            loss='mean_squared_error',
            metrics=['mae']
        )
        
        print("âœ… ëª¨ë¸ êµ¬ì„± ì™„ë£Œ!")
        print(f"   ğŸ“Š ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜: {self.model.count_params():,}")
        
        return self.model
    
    def load_or_create_model(self, retrain=False):
        """ëª¨ë¸ ë¡œë“œ ë˜ëŠ” ìƒì„±"""
        if os.path.exists(self.model_name) and not retrain:
            print("ğŸ“ ê¸°ì¡´ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...")
            self.model = load_model(self.model_name)
            self.is_trained = True
            print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
            return False  # í›ˆë ¨ ë¶ˆí•„ìš”
        else:
            print("ğŸ”§ ìƒˆ ëª¨ë¸ ìƒì„± ì¤‘...")
            self.build_model()
            return True  # í›ˆë ¨ í•„ìš”
    
    def train(self, X_train, y_train, epochs=100, batch_size=32, validation_split=0.1, callbacks=None):
        """ëª¨ë¸ í›ˆë ¨"""
        print(f"ğŸ¯ ëª¨ë¸ í›ˆë ¨ ì‹œì‘... ({datetime.now().strftime('%H:%M:%S')})")
        
        default_callbacks = [
            ModelCheckpoint(
                self.model_name, 
                save_best_only=True, 
                monitor='val_loss',
                verbose=1
            ),
            EarlyStopping(
                monitor='val_loss',
                patience=10,
                restore_best_weights=True
            )
        ]
        # ì™¸ë¶€ì—ì„œ ì „ë‹¬ëœ ì½œë°±ì„ ê¸°ë³¸ ì½œë°± ë’¤ì— ë³‘í•©
        if callbacks is None:
            callbacks_to_use = default_callbacks
        else:
            # ì¤‘ë³µ ë°©ì§€: íƒ€ì… ê¸°ë°˜ìœ¼ë¡œ ê°„ë‹¨ ë³‘í•©
            existing_types = {type(cb) for cb in default_callbacks}
            extra = [cb for cb in callbacks if type(cb) not in existing_types]
            callbacks_to_use = default_callbacks + extra
        
        history = self.model.fit(
            X_train, y_train,
            batch_size=batch_size,
            epochs=epochs,
            validation_split=validation_split,
            callbacks=callbacks_to_use,
            verbose=1
        )
        
        self.is_trained = True
        print(f"âœ… í›ˆë ¨ ì™„ë£Œ! ({datetime.now().strftime('%H:%M:%S')})")
        return history
    
    def evaluate(self, X_train, y_train, X_test, y_test):
        """ë‹¤ì¤‘ íŠ¹ì„± ëª¨ë¸ ì„±ëŠ¥ í‰ê°€"""
        if not self.is_trained:
            print("âŒ ëª¨ë¸ì´ í›ˆë ¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None
        
        print("ğŸ“Š ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ì¤‘...")
        
        # ì˜ˆì¸¡
        train_pred = self.model.predict(X_train, verbose=0)
        test_pred = self.model.predict(X_test, verbose=0)
        
        # íƒ€ê²Ÿ ìŠ¤ì¼€ì¼ëŸ¬ë¡œ ì—­ì •ê·œí™”
        train_pred = self.target_scaler.inverse_transform(train_pred)
        test_pred = self.target_scaler.inverse_transform(test_pred)
        y_train_actual = self.target_scaler.inverse_transform(y_train.reshape(-1, 1))
        y_test_actual = self.target_scaler.inverse_transform(y_test.reshape(-1, 1))
        
        # ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
        train_rmse = np.sqrt(mean_squared_error(y_train_actual, train_pred))
        test_rmse = np.sqrt(mean_squared_error(y_test_actual, test_pred))
        test_mae = mean_absolute_error(y_test_actual, test_pred)
        
        # ì¶”ê°€ ì„±ëŠ¥ ì§€í‘œ
        train_mape = np.mean(np.abs((y_train_actual - train_pred) / y_train_actual)) * 100
        test_mape = np.mean(np.abs((y_test_actual - test_pred) / y_test_actual)) * 100
        
        # RÂ² ìŠ¤ì½”ì–´
        from sklearn.metrics import r2_score
        train_r2 = r2_score(y_train_actual, train_pred)
        test_r2 = r2_score(y_test_actual, test_pred)
        
        results = {
            'train_rmse': train_rmse,
            'test_rmse': test_rmse,
            'test_mae': test_mae,
            'train_mape': train_mape,
            'test_mape': test_mape,
            'train_r2': train_r2,
            'test_r2': test_r2,
            'train_pred': train_pred,
            'test_pred': test_pred,
            'y_train_actual': y_train_actual,
            'y_test_actual': y_test_actual
        }
        
        print(f"\nğŸ“Š ì„±ëŠ¥ í‰ê°€ ê²°ê³¼:")
        print(f"   ğŸ¯ í›ˆë ¨ RMSE: ${train_rmse:.2f}")
        print(f"   ğŸ¯ í…ŒìŠ¤íŠ¸ RMSE: ${test_rmse:.2f}")
        print(f"   ğŸ“ í…ŒìŠ¤íŠ¸ MAE: ${test_mae:.2f}")
        print(f"   ğŸ“Š í…ŒìŠ¤íŠ¸ MAPE: {test_mape:.2f}%")
        print(f"   ğŸ“ˆ í…ŒìŠ¤íŠ¸ RÂ²: {test_r2:.4f}")
        print(f"   ğŸ” ì‚¬ìš©ëœ íŠ¹ì„±: {self.feature_columns}")
        
        return results
    
    def predict_future(self, scaled_data_tuple, price_data, days=5):
        """ë‹¤ì¤‘ íŠ¹ì„± ë¯¸ë˜ ê°€ê²© ì˜ˆì¸¡"""
        if not self.is_trained:
            print("âŒ ëª¨ë¸ì´ í›ˆë ¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None, None, None
        
        scaled_features, scaled_target = scaled_data_tuple
        
        # í›ˆë ¨ ë°ì´í„° ê¸°ê°„ ì •ë³´
        train_start_date = price_data.index[0]
        train_end_date = price_data.index[-1]
        
        # ì˜ˆì¸¡ ì‹œì‘ ë‚ ì§œ (ë§ˆì§€ë§‰ ë°ì´í„° ë‹¤ìŒ ë‚ )
        last_date = price_data.index[-1]
        prediction_dates = pd.date_range(
            start=last_date + pd.Timedelta(days=1), 
            periods=days, 
            freq='D'
        )
        
        print(f"\nğŸ”® ë‹¤ì¤‘ íŠ¹ì„± ì˜ˆì¸¡ ì •ë³´:")
        print(f"   ğŸ“… í›ˆë ¨ ë°ì´í„° ê¸°ê°„: {train_start_date.strftime('%Y-%m-%d')} ~ {train_end_date.strftime('%Y-%m-%d')}")
        print(f"   ğŸ“Š ì´ í›ˆë ¨ ì¼ìˆ˜: {len(price_data)}ì¼")
        print(f"   ğŸ¯ ì˜ˆì¸¡ ê¸°ê°„: {prediction_dates[0].strftime('%Y-%m-%d')} ~ {prediction_dates[-1].strftime('%Y-%m-%d')}")
        print(f"   ğŸ” ì‚¬ìš© íŠ¹ì„±: {self.feature_columns}")
        
        future_predictions = []
        # ë§ˆì§€ë§‰ ì‹œí€€ìŠ¤ (ëª¨ë“  íŠ¹ì„± í¬í•¨)
        last_sequence = scaled_features[-self.sequence_length:].copy()
        
        for day in range(days):
            # í˜„ì¬ ì‹œí€€ìŠ¤ë¡œ ì˜ˆì¸¡
            next_pred = self.model.predict(
                last_sequence.reshape(1, self.sequence_length, self.n_features), 
                verbose=0
            )
            future_predictions.append(next_pred[0, 0])
            
            # ë‹¤ìŒ ì‹œí€€ìŠ¤ë¥¼ ìœ„í•´ ì—…ë°ì´íŠ¸
            # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë‹¤ë¥¸ íŠ¹ì„±ë“¤ì˜ ë¯¸ë˜ê°’ë„ ì˜ˆì¸¡í•˜ê±°ë‚˜ ì¶”ì •í•´ì•¼ í•¨
            # ì—¬ê¸°ì„œëŠ” ë‹¨ìˆœí™”í•˜ì—¬ ë§ˆì§€ë§‰ ê°’ë“¤ì„ ì‚¬ìš©
            new_row = last_sequence[-1].copy()
            
            # íƒ€ê²Ÿ íŠ¹ì„± (Close)ì˜ ì¸ë±ìŠ¤ ì°¾ê¸°
            if 'Close' in self.feature_columns:
                close_idx = self.feature_columns.index('Close')
                new_row[close_idx] = next_pred[0, 0]
            
            # ì‹œí€€ìŠ¤ ì—…ë°ì´íŠ¸ (í•œ ì¹¸ì”© ì´ë™)
            last_sequence = np.vstack([last_sequence[1:], new_row])
        
        # íƒ€ê²Ÿ ìŠ¤ì¼€ì¼ëŸ¬ë¡œ ì—­ì •ê·œí™”
        predictions = self.target_scaler.inverse_transform(
            np.array(future_predictions).reshape(-1, 1)
        )
        
        return predictions, prediction_dates, (train_start_date, train_end_date)
    
    def plot_results(self, price_data, results, train_size, save_plots=True):
        """ê²°ê³¼ ì‹œê°í™”"""
        plt.figure(figsize=(15, 8))
        
        # ì „ì²´ ë°ì´í„°
        plt.subplot(2, 1, 1)
        plt.plot(price_data.index, price_data.values, 
                label='Actual Gold Price', alpha=0.7, linewidth=1)
        plt.axvline(x=price_data.index[train_size], color='red', 
                   linestyle='--', label='Train/Test Split', alpha=0.7)
        plt.title('Gold Price - Full Data', fontsize=14)
        plt.legend(fontsize=10)
        plt.grid(True, alpha=0.3)
        
        # í…ŒìŠ¤íŠ¸ êµ¬ê°„ ì˜ˆì¸¡ ê²°ê³¼
        plt.subplot(2, 1, 2)
        test_dates = price_data.index[train_size + self.sequence_length:]
        plt.plot(test_dates, results['y_test_actual'], 
                label='Actual Price', marker='o', markersize=1.5, linewidth=1)
        plt.plot(test_dates, results['test_pred'], 
                label='Predicted Price', marker='x', markersize=1.5, linewidth=1)
        plt.title(f'Test Results (RMSE: ${results["test_rmse"]:.2f})', fontsize=14)
        plt.legend(fontsize=10)
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        
        if save_plots:
            import os
            # í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬ì— ë”°ë¼ ê²½ë¡œ ì¡°ì •
            if os.path.basename(os.getcwd()) == 'analysis':
                save_path = '../results/prediction_results.png'
            else:
                save_path = 'results/prediction_results.png'
            plt.savefig(save_path, dpi=150, bbox_inches='tight')
            plt.close()
            print(f"ğŸ“Š ì˜ˆì¸¡ ê²°ê³¼ ì°¨íŠ¸ ì €ì¥ë¨: {save_path}")
            return save_path
        else:
            plt.show()

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    print("ğŸ§ª Gold Prediction Model í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ ë°ì´í„° ìƒì„±
    from datetime import datetime, timedelta
    
    # í…ŒìŠ¤íŠ¸ìš© ê¸ˆ ê°€ê²© ë°ì´í„° ìƒì„± (ì‹¤ì œë¡œëŠ” gold_data_managerì—ì„œ ê°€ì ¸ì˜´)
    dates = pd.date_range(start='2020-01-01', end='2023-12-31', freq='D')
    np.random.seed(42)
    base_price = 1800
    price_trend = np.cumsum(np.random.randn(len(dates)) * 5) + base_price
    test_data = pd.Series(price_trend, index=dates, name='gold_price')
    
    print(f"ğŸ“Š í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_data)}ì¼ ì¹˜ ê¸ˆ ê°€ê²©")
    
    # ëª¨ë¸ ì´ˆê¸°í™”
    model = GoldPredictionModel()
    
    try:
        # ë°ì´í„° ì¤€ë¹„
        X_train, y_train, X_test, y_test, scaled_data, train_size = model.prepare_data(test_data)
        
        # ëª¨ë¸ ë¡œë“œ ë˜ëŠ” ìƒì„±
        needs_training = model.load_or_create_model()
        
        if needs_training:
            print("ğŸ¯ ëª¨ë¸ í›ˆë ¨ì´ í•„ìš”í•©ë‹ˆë‹¤...")
            history = model.train(X_train, y_train, epochs=50, batch_size=16)
        
        # ëª¨ë¸ í‰ê°€
        results = model.evaluate(X_train, y_train, X_test, y_test)
        
        if results:
            # ê²°ê³¼ ì‹œê°í™”
            model.plot_results(test_data, results, train_size)
            
            # ë¯¸ë˜ ì˜ˆì¸¡
            future_pred, pred_dates, train_info = model.predict_future(scaled_data, test_data, days=7)
            if future_pred is not None:
                print(f"\nğŸ”® í–¥í›„ 7ì¼ ê¸ˆ ê°€ê²© ì˜ˆì¸¡:")
                for i, (price, date) in enumerate(zip(future_pred.flatten(), pred_dates), 1):
                    print(f"   {i}ì¼ í›„ ({date.strftime('%Y-%m-%d')}): ${price:.2f}")
            else:
                print("âŒ ì˜ˆì¸¡ ì‹¤íŒ¨")
        
        print("\nâœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()